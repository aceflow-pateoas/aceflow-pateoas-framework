#!/usr/bin/env python3
"""
AceFlow v2.0 åŸºäºè§„åˆ™çš„è½»é‡çº§å†³ç­–å¼•æ“
ä¸“ä¸ºAgentå·¥å…·é›†æˆè®¾è®¡ï¼Œæ— éœ€å¤–éƒ¨LLM
"""

import json
import yaml
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

# ä»»åŠ¡ç±»å‹æšä¸¾
class TaskType(Enum):
    FEATURE_DEVELOPMENT = "feature_development"
    BUG_FIX = "bug_fix"
    REFACTORING = "refactoring"
    TESTING = "testing"
    DOCUMENTATION = "documentation"
    RESEARCH = "research"
    ARCHITECTURE = "architecture"
    DEPLOYMENT = "deployment"
    MAINTENANCE = "maintenance"

# é¡¹ç›®å¤æ‚åº¦æšä¸¾
class ProjectComplexity(Enum):
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    ENTERPRISE = "enterprise"

# æµç¨‹æ¨¡å¼æšä¸¾
class FlowMode(Enum):
    MINIMAL = "minimal"
    STANDARD = "standard"
    COMPLETE = "complete"

@dataclass
class ProjectProfile:
    """é¡¹ç›®ç‰¹å¾ç”»åƒ"""
    project_type: str = "unknown"
    team_size: int = 1
    complexity: ProjectComplexity = ProjectComplexity.SIMPLE
    tech_stack: List[str] = None
    has_tests: bool = False
    has_ci_cd: bool = False
    has_documentation: bool = False
    git_activity: str = "low"  # low, medium, high
    file_count: int = 0
    
    def __post_init__(self):
        if self.tech_stack is None:
            self.tech_stack = []

@dataclass
class DecisionResult:
    """å†³ç­–ç»“æœ"""
    recommended_flow: str
    confidence: float
    reasoning: str
    steps: List[str]
    estimated_hours: int
    alternatives: List[Dict[str, Any]]
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

class PatternMatcher:
    """ä»»åŠ¡æ¨¡å¼åŒ¹é…å™¨"""
    
    def __init__(self):
        self.patterns = {
            TaskType.BUG_FIX: [
                r'(fix|bug|error|issue|problem|crash|fail)',
                r'(ä¿®å¤|é”™è¯¯|é—®é¢˜|æ•…éšœ|å´©æºƒ|å¤±è´¥)',
                r'(debug|debugging)',
                r'(not working|broken|incorrect)',
                r'(æ— æ³•|ä¸èƒ½|æ— æ•ˆ|å¤±æ•ˆ)'
            ],
            TaskType.FEATURE_DEVELOPMENT: [
                r'(add|new|create|implement|build|develop)',
                r'(feature|functionality|capability|module|component)',
                r'(æ–°å¢|æ·»åŠ |åˆ›å»º|å®ç°|å¼€å‘|æ„å»º)',
                r'(åŠŸèƒ½|ç‰¹æ€§|æ¨¡å—|ç»„ä»¶|æ¥å£)',
                r'(enhancement|improvement|upgrade)',
                r'(å¢å¼º|æ”¹è¿›|å‡çº§|æ‰©å±•)'
            ],
            TaskType.REFACTORING: [
                r'(refactor|refactoring|restructure|reorganize)',
                r'(optimize|optimization|improve|clean)',
                r'(é‡æ„|é‡ç»„|ä¼˜åŒ–|æ”¹è¿›|æ•´ç†)',
                r'(code quality|performance|maintainability)',
                r'(ä»£ç è´¨é‡|æ€§èƒ½|å¯ç»´æŠ¤æ€§)'
            ],
            TaskType.TESTING: [
                r'(test|testing|unit test|integration test)',
                r'(æµ‹è¯•|å•å…ƒæµ‹è¯•|é›†æˆæµ‹è¯•|æµ‹è¯•ç”¨ä¾‹)',
                r'(coverage|test coverage|qa)',
                r'(è¦†ç›–ç‡|æµ‹è¯•è¦†ç›–ç‡|è´¨é‡ä¿è¯)',
                r'(verify|validation|check)',
                r'(éªŒè¯|æ ¡éªŒ|æ£€æŸ¥)'
            ],
            TaskType.DOCUMENTATION: [
                r'(doc|docs|documentation|readme|guide)',
                r'(æ–‡æ¡£|è¯´æ˜|æŒ‡å—|æ‰‹å†Œ)',
                r'(comment|comments|api doc)',
                r'(æ³¨é‡Š|APIæ–‡æ¡£|æ¥å£æ–‡æ¡£)',
                r'(tutorial|example|demo)',
                r'(æ•™ç¨‹|ç¤ºä¾‹|æ¼”ç¤º)'
            ],
            TaskType.RESEARCH: [
                r'(research|investigate|explore|study)',
                r'(è°ƒç ”|ç ”ç©¶|æ¢ç´¢|åˆ†æ)',
                r'(poc|proof of concept|spike)',
                r'(åŸå‹|æ¦‚å¿µéªŒè¯|æŠ€æœ¯éªŒè¯)',
                r'(evaluation|comparison|analysis)',
                r'(è¯„ä¼°|æ¯”è¾ƒ|åˆ†æ)'
            ],
            TaskType.ARCHITECTURE: [
                r'(architecture|design|structure|framework)',
                r'(æ¶æ„|è®¾è®¡|ç»“æ„|æ¡†æ¶)',
                r'(system design|technical design)',
                r'(ç³»ç»Ÿè®¾è®¡|æŠ€æœ¯è®¾è®¡)',
                r'(blueprint|plan|specification)',
                r'(è“å›¾|è§„åˆ’|è§„èŒƒ)'
            ],
            TaskType.DEPLOYMENT: [
                r'(deploy|deployment|release|publish)',
                r'(éƒ¨ç½²|å‘å¸ƒ|ä¸Šçº¿|å‘ç‰ˆ)',
                r'(ci/cd|pipeline|build)',
                r'(ç¯å¢ƒ|ç”Ÿäº§ç¯å¢ƒ|æœåŠ¡å™¨)',
                r'(docker|kubernetes|container)',
                r'(å®¹å™¨|å®¹å™¨åŒ–|ç¼–æ’)'
            ],
            TaskType.MAINTENANCE: [
                r'(maintain|maintenance|update|upgrade)',
                r'(ç»´æŠ¤|æ›´æ–°|å‡çº§|è¿ç§»)',
                r'(security|vulnerability|patch)',
                r'(å®‰å…¨|æ¼æ´|è¡¥ä¸)',
                r'(dependency|library|framework)',
                r'(ä¾èµ–|åº“|æ¡†æ¶)'
            ]
        }
    
    def classify_task(self, task_description: str) -> TaskType:
        """åŸºäºæ¨¡å¼åŒ¹é…åˆ†ç±»ä»»åŠ¡"""
        if not task_description:
            return TaskType.FEATURE_DEVELOPMENT
        
        task_lower = task_description.lower()
        scores = {}
        
        for task_type, patterns in self.patterns.items():
            score = 0
            for pattern in patterns:
                if re.search(pattern, task_lower):
                    score += 1
            scores[task_type] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ä»»åŠ¡ç±»å‹
        if scores:
            best_type = max(scores, key=scores.get)
            if scores[best_type] > 0:
                return best_type
        
        return TaskType.FEATURE_DEVELOPMENT

class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨"""
    
    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path.cwd()
        self.aceflow_dir = self.project_root / ".aceflow"
    
    def analyze_project(self) -> ProjectProfile:
        """åˆ†æé¡¹ç›®ç‰¹å¾"""
        profile = ProjectProfile()
        
        # åˆ†æé¡¹ç›®ç±»å‹
        profile.project_type = self._detect_project_type()
        
        # åˆ†æå›¢é˜Ÿè§„æ¨¡
        profile.team_size = self._estimate_team_size()
        
        # åˆ†æå¤æ‚åº¦
        profile.complexity = self._assess_complexity()
        
        # åˆ†ææŠ€æœ¯æ ˆ
        profile.tech_stack = self._detect_tech_stack()
        
        # åˆ†æé¡¹ç›®ç‰¹å¾
        profile.has_tests = self._has_tests()
        profile.has_ci_cd = self._has_ci_cd()
        profile.has_documentation = self._has_documentation()
        profile.git_activity = self._assess_git_activity()
        profile.file_count = self._count_files()
        
        return profile
    
    def _detect_project_type(self) -> str:
        """æ£€æµ‹é¡¹ç›®ç±»å‹"""
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_file = self.aceflow_dir / "config.yaml"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    if 'project' in config and 'project_type' in config['project']:
                        return config['project']['project_type']
            except:
                pass
        
        # åŸºäºæ–‡ä»¶æ£€æµ‹
        if (self.project_root / "package.json").exists():
            return "web"
        elif (self.project_root / "requirements.txt").exists() or (self.project_root / "pyproject.toml").exists():
            return "python"
        elif (self.project_root / "pom.xml").exists():
            return "java"
        elif (self.project_root / "Cargo.toml").exists():
            return "rust"
        elif (self.project_root / "go.mod").exists():
            return "go"
        elif (self.project_root / "pubspec.yaml").exists():
            return "flutter"
        else:
            return "unknown"
    
    def _estimate_team_size(self) -> int:
        """ä¼°ç®—å›¢é˜Ÿè§„æ¨¡"""
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        config_file = self.aceflow_dir / "config.yaml"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    if 'project' in config and 'team_size' in config['project']:
                        team_size_str = config['project']['team_size']
                        if isinstance(team_size_str, int):
                            return team_size_str
                        elif isinstance(team_size_str, str):
                            # è§£æ "1-5äºº" æ ¼å¼
                            import re
                            match = re.search(r'(\d+)', team_size_str)
                            if match:
                                return int(match.group(1))
            except:
                pass
        
        # åŸºäºGitæäº¤è€…æ•°é‡ä¼°ç®—
        try:
            import subprocess
            result = subprocess.run(
                ["git", "log", "--pretty=format:%ae", "--since=3 months ago"],
                capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0:
                contributors = set(result.stdout.strip().split('\n'))
                return max(1, len(contributors))
        except:
            pass
        
        return 1
    
    def _assess_complexity(self) -> ProjectComplexity:
        """è¯„ä¼°é¡¹ç›®å¤æ‚åº¦"""
        score = 0
        
        # æ–‡ä»¶æ•°é‡
        file_count = self._count_files()
        if file_count > 100:
            score += 2
        elif file_count > 50:
            score += 1
        
        # ç›®å½•æ·±åº¦
        max_depth = self._get_max_directory_depth()
        if max_depth > 5:
            score += 2
        elif max_depth > 3:
            score += 1
        
        # æŠ€æœ¯æ ˆå¤æ‚åº¦
        tech_stack = self._detect_tech_stack()
        if len(tech_stack) > 5:
            score += 2
        elif len(tech_stack) > 3:
            score += 1
        
        # é…ç½®æ–‡ä»¶æ•°é‡
        config_files = self._count_config_files()
        if config_files > 10:
            score += 2
        elif config_files > 5:
            score += 1
        
        # ä¾èµ–æ•°é‡
        dependencies = self._count_dependencies()
        if dependencies > 50:
            score += 2
        elif dependencies > 20:
            score += 1
        
        # æ ¹æ®å¾—åˆ†ç¡®å®šå¤æ‚åº¦
        if score >= 7:
            return ProjectComplexity.ENTERPRISE
        elif score >= 5:
            return ProjectComplexity.COMPLEX
        elif score >= 3:
            return ProjectComplexity.MODERATE
        else:
            return ProjectComplexity.SIMPLE
    
    def _detect_tech_stack(self) -> List[str]:
        """æ£€æµ‹æŠ€æœ¯æ ˆ"""
        tech_stack = []
        
        # æ£€æŸ¥å¸¸è§æ–‡ä»¶
        tech_indicators = {
            "package.json": ["JavaScript", "Node.js"],
            "requirements.txt": ["Python"],
            "pyproject.toml": ["Python"],
            "pom.xml": ["Java", "Maven"],
            "build.gradle": ["Java", "Gradle"],
            "Cargo.toml": ["Rust"],
            "go.mod": ["Go"],
            "pubspec.yaml": ["Flutter", "Dart"],
            "composer.json": ["PHP"],
            "Gemfile": ["Ruby"],
            "mix.exs": ["Elixir"],
            "project.clj": ["Clojure"],
            "*.csproj": ["C#", ".NET"],
            "Dockerfile": ["Docker"],
            "docker-compose.yml": ["Docker Compose"],
            "k8s": ["Kubernetes"],
            ".github/workflows": ["GitHub Actions"],
            ".gitlab-ci.yml": ["GitLab CI"],
            "terraform": ["Terraform"],
            "ansible": ["Ansible"]
        }
        
        for file_pattern, technologies in tech_indicators.items():
            if '*' in file_pattern:
                # é€šé…ç¬¦åŒ¹é…
                pattern = file_pattern.replace('*', '**/*')
                if list(self.project_root.glob(pattern)):
                    tech_stack.extend(technologies)
            else:
                # ç²¾ç¡®åŒ¹é…
                if (self.project_root / file_pattern).exists():
                    tech_stack.extend(technologies)
        
        return list(set(tech_stack))
    
    def _count_files(self) -> int:
        """ç»Ÿè®¡æ–‡ä»¶æ•°é‡ï¼ˆæ’é™¤éšè—æ–‡ä»¶å’Œå¸¸è§å¿½ç•¥ç›®å½•ï¼‰"""
        ignore_dirs = {'.git', '.aceflow', 'node_modules', '__pycache__', '.pytest_cache', 'target', 'build', 'dist'}
        ignore_files = {'.gitignore', '.DS_Store', 'Thumbs.db'}
        
        count = 0
        for file_path in self.project_root.rglob('*'):
            if file_path.is_file():
                # æ£€æŸ¥æ˜¯å¦åœ¨å¿½ç•¥ç›®å½•ä¸­
                if any(ignore_dir in file_path.parts for ignore_dir in ignore_dirs):
                    continue
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¿½ç•¥æ–‡ä»¶
                if file_path.name in ignore_files:
                    continue
                count += 1
        
        return count
    
    def _get_max_directory_depth(self) -> int:
        """è·å–ç›®å½•æœ€å¤§æ·±åº¦"""
        max_depth = 0
        for path in self.project_root.rglob('*'):
            if path.is_dir():
                depth = len(path.relative_to(self.project_root).parts)
                max_depth = max(max_depth, depth)
        return max_depth
    
    def _count_config_files(self) -> int:
        """ç»Ÿè®¡é…ç½®æ–‡ä»¶æ•°é‡"""
        config_patterns = [
            "*.json", "*.yaml", "*.yml", "*.toml", "*.ini", "*.cfg", "*.config",
            "*.properties", "*.env", "Dockerfile", "docker-compose*"
        ]
        
        count = 0
        for pattern in config_patterns:
            count += len(list(self.project_root.glob(pattern)))
        
        return count
    
    def _count_dependencies(self) -> int:
        """ç»Ÿè®¡ä¾èµ–æ•°é‡"""
        count = 0
        
        # package.json
        package_json = self.project_root / "package.json"
        if package_json.exists():
            try:
                with open(package_json, 'r') as f:
                    data = json.load(f)
                    count += len(data.get('dependencies', {}))
                    count += len(data.get('devDependencies', {}))
            except:
                pass
        
        # requirements.txt
        requirements = self.project_root / "requirements.txt"
        if requirements.exists():
            try:
                with open(requirements, 'r') as f:
                    lines = f.readlines()
                    count += len([line for line in lines if line.strip() and not line.startswith('#')])
            except:
                pass
        
        # pyproject.toml
        pyproject = self.project_root / "pyproject.toml"
        if pyproject.exists():
            try:
                import toml
                with open(pyproject, 'r') as f:
                    data = toml.load(f)
                    if 'tool' in data and 'poetry' in data['tool'] and 'dependencies' in data['tool']['poetry']:
                        count += len(data['tool']['poetry']['dependencies'])
            except:
                pass
        
        return count
    
    def _has_tests(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ–‡ä»¶"""
        test_patterns = [
            "**/test_*.py", "**/tests/*.py", "**/*_test.py",
            "**/test*.js", "**/tests/*.js", "**/*.test.js", "**/*.spec.js",
            "**/test*.java", "**/tests/*.java", "**/*Test.java",
            "**/test*.go", "**/*_test.go"
        ]
        
        for pattern in test_patterns:
            if list(self.project_root.glob(pattern)):
                return True
        
        return False
    
    def _has_ci_cd(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰CI/CDé…ç½®"""
        ci_cd_files = [
            ".github/workflows",
            ".gitlab-ci.yml",
            ".travis.yml",
            "circle.yml",
            "appveyor.yml",
            "jenkins.yml",
            "Jenkinsfile"
        ]
        
        for file_path in ci_cd_files:
            if (self.project_root / file_path).exists():
                return True
        
        return False
    
    def _has_documentation(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£"""
        doc_files = [
            "README.md", "README.rst", "README.txt",
            "docs", "doc", "documentation",
            "CHANGELOG.md", "CHANGELOG.rst",
            "API.md", "api.md"
        ]
        
        for file_path in doc_files:
            if (self.project_root / file_path).exists():
                return True
        
        return False
    
    def _assess_git_activity(self) -> str:
        """è¯„ä¼°Gitæ´»åŠ¨æ°´å¹³"""
        try:
            import subprocess
            from datetime import datetime, timedelta
            
            # æœ€è¿‘3ä¸ªæœˆçš„æäº¤æ•°
            three_months_ago = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
            result = subprocess.run(
                ["git", "log", "--oneline", f"--since={three_months_ago}"],
                capture_output=True, text=True, cwd=self.project_root
            )
            
            if result.returncode == 0:
                commit_count = len(result.stdout.strip().split('\n'))
                if commit_count > 100:
                    return "high"
                elif commit_count > 20:
                    return "medium"
                else:
                    return "low"
        except:
            pass
        
        return "low"

class RuleEngine:
    """è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.rules = self._load_rules()
    
    def _load_rules(self) -> Dict[str, Any]:
        """åŠ è½½å†³ç­–è§„åˆ™"""
        return {
            "flow_rules": {
                "minimal": {
                    "conditions": [
                        {"field": "task_type", "operator": "in", "value": ["BUG_FIX", "MAINTENANCE", "DOCUMENTATION"]},
                        {"field": "team_size", "operator": "<=", "value": 3},
                        {"field": "complexity", "operator": "==", "value": "SIMPLE"},
                        {"field": "urgency", "operator": "==", "value": "high"}
                    ],
                    "weight": 1.0
                },
                "standard": {
                    "conditions": [
                        {"field": "task_type", "operator": "in", "value": ["FEATURE_DEVELOPMENT", "TESTING", "REFACTORING"]},
                        {"field": "team_size", "operator": "between", "value": [3, 8]},
                        {"field": "complexity", "operator": "in", "value": ["MODERATE", "COMPLEX"]},
                        {"field": "has_tests", "operator": "==", "value": True}
                    ],
                    "weight": 1.0
                },
                "complete": {
                    "conditions": [
                        {"field": "task_type", "operator": "in", "value": ["ARCHITECTURE", "RESEARCH", "DEPLOYMENT"]},
                        {"field": "team_size", "operator": ">", "value": 8},
                        {"field": "complexity", "operator": "==", "value": "ENTERPRISE"},
                        {"field": "has_ci_cd", "operator": "==", "value": True}
                    ],
                    "weight": 1.0
                }
            },
            "estimation_rules": {
                "BUG_FIX": {"base_hours": 4, "complexity_factor": 1.2},
                "FEATURE_DEVELOPMENT": {"base_hours": 16, "complexity_factor": 1.5},
                "REFACTORING": {"base_hours": 8, "complexity_factor": 1.3},
                "TESTING": {"base_hours": 6, "complexity_factor": 1.1},
                "DOCUMENTATION": {"base_hours": 4, "complexity_factor": 1.0},
                "RESEARCH": {"base_hours": 12, "complexity_factor": 1.4},
                "ARCHITECTURE": {"base_hours": 24, "complexity_factor": 1.6},
                "DEPLOYMENT": {"base_hours": 8, "complexity_factor": 1.2},
                "MAINTENANCE": {"base_hours": 6, "complexity_factor": 1.1}
            }
        }
    
    def evaluate_flow_rules(self, task_type: TaskType, project_profile: ProjectProfile, 
                           urgency: str = "medium") -> Dict[str, float]:
        """è¯„ä¼°æµç¨‹è§„åˆ™ï¼Œè¿”å›å„æµç¨‹çš„åŒ¹é…åˆ†æ•°"""
        scores = {}
        
        # æ„å»ºè¯„ä¼°ä¸Šä¸‹æ–‡
        context = {
            "task_type": task_type.value.upper(),
            "team_size": project_profile.team_size,
            "complexity": project_profile.complexity.value.upper(),
            "has_tests": project_profile.has_tests,
            "has_ci_cd": project_profile.has_ci_cd,
            "urgency": urgency
        }
        
        # è¯„ä¼°æ¯ä¸ªæµç¨‹
        for flow_name, flow_rule in self.rules["flow_rules"].items():
            score = self._evaluate_conditions(flow_rule["conditions"], context)
            scores[flow_name] = score * flow_rule["weight"]
        
        return scores
    
    def _evaluate_conditions(self, conditions: List[Dict], context: Dict) -> float:
        """è¯„ä¼°æ¡ä»¶é›†åˆï¼Œè¿”å›åŒ¹é…åˆ†æ•°"""
        if not conditions:
            return 0.0
        
        matched_count = 0
        total_count = len(conditions)
        
        for condition in conditions:
            if self._evaluate_single_condition(condition, context):
                matched_count += 1
        
        return matched_count / total_count
    
    def _evaluate_single_condition(self, condition: Dict, context: Dict) -> bool:
        """è¯„ä¼°å•ä¸ªæ¡ä»¶"""
        field = condition["field"]
        operator = condition["operator"]
        value = condition["value"]
        
        if field not in context:
            return False
        
        context_value = context[field]
        
        if operator == "==":
            return context_value == value
        elif operator == "!=":
            return context_value != value
        elif operator == "<":
            return context_value < value
        elif operator == "<=":
            return context_value <= value
        elif operator == ">":
            return context_value > value
        elif operator == ">=":
            return context_value >= value
        elif operator == "in":
            return context_value in value
        elif operator == "not_in":
            return context_value not in value
        elif operator == "between":
            return value[0] <= context_value <= value[1]
        else:
            return False
    
    def estimate_duration(self, task_type: TaskType, project_profile: ProjectProfile) -> int:
        """ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´"""
        task_key = task_type.value.upper()
        
        if task_key not in self.rules["estimation_rules"]:
            return 8  # é»˜è®¤8å°æ—¶
        
        rule = self.rules["estimation_rules"][task_key]
        base_hours = rule["base_hours"]
        complexity_factor = rule["complexity_factor"]
        
        # åº”ç”¨å¤æ‚åº¦å› å­
        complexity_multiplier = {
            ProjectComplexity.SIMPLE: 1.0,
            ProjectComplexity.MODERATE: 1.2,
            ProjectComplexity.COMPLEX: 1.5,
            ProjectComplexity.ENTERPRISE: 2.0
        }
        
        hours = base_hours * complexity_factor * complexity_multiplier[project_profile.complexity]
        
        # åº”ç”¨å›¢é˜Ÿè§„æ¨¡å› å­
        if project_profile.team_size > 5:
            hours *= 1.2  # å¤§å›¢é˜Ÿåè°ƒæˆæœ¬
        elif project_profile.team_size == 1:
            hours *= 0.9  # å•äººé¡¹ç›®æ•ˆç‡
        
        return int(hours)

class RuleBasedDecisionEngine:
    """åŸºäºè§„åˆ™çš„å†³ç­–å¼•æ“"""
    
    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path.cwd()
        self.pattern_matcher = PatternMatcher()
        self.project_analyzer = ProjectAnalyzer(self.project_root)
        self.rule_engine = RuleEngine()
    
    def make_decision(self, task_input: str, context: Dict[str, Any] = None) -> DecisionResult:
        """åšå‡ºå†³ç­–"""
        if context is None:
            context = {}
        
        # 1. ä»»åŠ¡åˆ†ç±»
        task_type = self.pattern_matcher.classify_task(task_input)
        
        # 2. é¡¹ç›®åˆ†æ
        project_profile = self.project_analyzer.analyze_project()
        
        # 3. åº”ç”¨ä¸Šä¸‹æ–‡è¦†ç›–
        self._apply_context_overrides(project_profile, context)
        
        # 4. æµç¨‹æ¨è
        flow_scores = self.rule_engine.evaluate_flow_rules(
            task_type, project_profile, context.get("urgency", "medium")
        )
        
        # 5. é€‰æ‹©æœ€ä½³æµç¨‹
        recommended_flow = max(flow_scores, key=flow_scores.get)
        confidence = flow_scores[recommended_flow]
        
        # 6. ç”Ÿæˆæ­¥éª¤
        steps = self._generate_steps(recommended_flow)
        
        # 7. ä¼°ç®—æ—¶é—´
        estimated_hours = self.rule_engine.estimate_duration(task_type, project_profile)
        
        # 8. ç”Ÿæˆæ¨ç†è§£é‡Š
        reasoning = self._generate_reasoning(task_type, project_profile, recommended_flow, confidence)
        
        # 9. æä¾›æ›¿ä»£æ–¹æ¡ˆ
        alternatives = self._generate_alternatives(flow_scores, recommended_flow)
        
        # 10. å…ƒæ•°æ®
        metadata = {
            "task_type": task_type.value,
            "project_profile": asdict(project_profile),
            "flow_scores": flow_scores,
            "timestamp": datetime.now().isoformat()
        }
        
        return DecisionResult(
            recommended_flow=recommended_flow,
            confidence=confidence,
            reasoning=reasoning,
            steps=steps,
            estimated_hours=estimated_hours,
            alternatives=alternatives,
            metadata=metadata
        )
    
    def _apply_context_overrides(self, project_profile: ProjectProfile, context: Dict[str, Any]):
        """åº”ç”¨ä¸Šä¸‹æ–‡è¦†ç›–"""
        if "team_size" in context:
            project_profile.team_size = context["team_size"]
        if "project_type" in context:
            project_profile.project_type = context["project_type"]
        if "complexity" in context:
            if isinstance(context["complexity"], str):
                project_profile.complexity = ProjectComplexity(context["complexity"])
    
    def _generate_steps(self, flow_mode: str) -> List[str]:
        """ç”Ÿæˆæµç¨‹æ­¥éª¤"""
        flow_steps = {
            "minimal": [
                "Planning (P): éœ€æ±‚åˆ†æå’Œä»»åŠ¡è§„åˆ’",
                "Development (D): å¼€å‘å®ç°",
                "Review (R): ä»£ç å®¡æŸ¥å’Œæµ‹è¯•éªŒè¯"
            ],
            "standard": [
                "Planning 1 (P1): éœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡",
                "Planning 2 (P2): è¯¦ç»†è®¾è®¡å’Œä»»åŠ¡åˆ†è§£",
                "Development 1 (D1): æ ¸å¿ƒåŠŸèƒ½å¼€å‘",
                "Development 2 (D2): é›†æˆå’Œä¼˜åŒ–",
                "Review 1 (R1): æµ‹è¯•å’Œè´¨é‡éªŒè¯"
            ],
            "complete": [
                "Strategy (S1): é¡¹ç›®ç­–ç•¥å’Œç›®æ ‡åˆ¶å®š",
                "Analysis (S2): éœ€æ±‚åˆ†æå’Œå¯è¡Œæ€§ç ”ç©¶",
                "Design (S3): ç³»ç»Ÿè®¾è®¡å’Œæ¶æ„è§„åˆ’",
                "Planning (S4): è¯¦ç»†è®¡åˆ’å’Œèµ„æºåˆ†é…",
                "Development (S5): å¼€å‘å®ç°",
                "Integration (S6): ç³»ç»Ÿé›†æˆå’Œè”è°ƒ",
                "Testing (S7): å…¨é¢æµ‹è¯•å’Œè´¨é‡ä¿è¯",
                "Deployment (S8): éƒ¨ç½²å’Œä¸Šçº¿"
            ]
        }
        
        return flow_steps.get(flow_mode, flow_steps["standard"])
    
    def _generate_reasoning(self, task_type: TaskType, project_profile: ProjectProfile, 
                          recommended_flow: str, confidence: float) -> str:
        """ç”Ÿæˆæ¨ç†è§£é‡Š"""
        reasons = []
        
        # ä»»åŠ¡ç±»å‹ç›¸å…³æ¨ç†
        if task_type == TaskType.BUG_FIX:
            reasons.append("è¿™æ˜¯ä¸€ä¸ªbugä¿®å¤ä»»åŠ¡ï¼Œé€šå¸¸éœ€è¦å¿«é€Ÿå“åº”")
        elif task_type == TaskType.FEATURE_DEVELOPMENT:
            reasons.append("è¿™æ˜¯åŠŸèƒ½å¼€å‘ä»»åŠ¡ï¼Œéœ€è¦å®Œæ•´çš„å¼€å‘æµç¨‹")
        elif task_type == TaskType.ARCHITECTURE:
            reasons.append("è¿™æ˜¯æ¶æ„è®¾è®¡ä»»åŠ¡ï¼Œéœ€è¦ä¸¥æ ¼çš„è§„åˆ’å’Œå®¡æŸ¥")
        
        # é¡¹ç›®ç‰¹å¾ç›¸å…³æ¨ç†
        if project_profile.team_size <= 3:
            reasons.append("å°å›¢é˜Ÿé€‚åˆè½»é‡çº§æµç¨‹")
        elif project_profile.team_size > 8:
            reasons.append("å¤§å›¢é˜Ÿéœ€è¦æ›´ä¸¥æ ¼çš„åè°ƒæµç¨‹")
        
        if project_profile.complexity == ProjectComplexity.SIMPLE:
            reasons.append("é¡¹ç›®å¤æ‚åº¦è¾ƒä½ï¼Œå¯ä»¥ç®€åŒ–æµç¨‹")
        elif project_profile.complexity == ProjectComplexity.ENTERPRISE:
            reasons.append("ä¼ä¸šçº§é¡¹ç›®éœ€è¦å®Œæ•´çš„è´¨é‡ä¿è¯æµç¨‹")
        
        # æŠ€æœ¯ç‰¹å¾ç›¸å…³æ¨ç†
        if project_profile.has_tests:
            reasons.append("é¡¹ç›®æœ‰æµ‹è¯•åŸºç¡€ï¼Œæ”¯æŒæ ‡å‡†åŒ–æµç¨‹")
        if project_profile.has_ci_cd:
            reasons.append("é¡¹ç›®æœ‰CI/CDæ”¯æŒï¼Œé€‚åˆè‡ªåŠ¨åŒ–æµç¨‹")
        
        # ç½®ä¿¡åº¦è§£é‡Š
        if confidence > 0.8:
            confidence_text = "é«˜ç½®ä¿¡åº¦æ¨è"
        elif confidence > 0.6:
            confidence_text = "ä¸­ç­‰ç½®ä¿¡åº¦æ¨è"
        else:
            confidence_text = "ä½ç½®ä¿¡åº¦æ¨èï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´"
        
        reasoning = f"æ¨èä½¿ç”¨{recommended_flow}æµç¨‹ï¼Œ{confidence_text}ã€‚"
        if reasons:
            reasoning += "ä¸»è¦åŸå› ï¼š" + "ï¼Œ".join(reasons) + "ã€‚"
        
        return reasoning
    
    def _generate_alternatives(self, flow_scores: Dict[str, float], 
                             recommended_flow: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []
        
        # æ’åºå¹¶æ’é™¤æ¨èæµç¨‹
        sorted_flows = sorted(
            [(flow, score) for flow, score in flow_scores.items() if flow != recommended_flow],
            key=lambda x: x[1], reverse=True
        )
        
        for flow, score in sorted_flows[:2]:  # æœ€å¤š2ä¸ªæ›¿ä»£æ–¹æ¡ˆ
            reason = self._get_alternative_reason(flow, score)
            alternatives.append({
                "flow": flow,
                "confidence": score,
                "reason": reason
            })
        
        return alternatives
    
    def _get_alternative_reason(self, flow: str, score: float) -> str:
        """è·å–æ›¿ä»£æ–¹æ¡ˆçš„æ¨èç†ç”±"""
        reasons = {
            "minimal": "å¦‚æœæ—¶é—´ç´§è¿«æˆ–å›¢é˜Ÿç»éªŒä¸°å¯Œï¼Œå¯ä»¥é€‰æ‹©è½»é‡çº§æµç¨‹",
            "standard": "å¦‚æœéœ€è¦å¹³è¡¡æ•ˆç‡å’Œè´¨é‡ï¼Œå¯ä»¥é€‰æ‹©æ ‡å‡†æµç¨‹",
            "complete": "å¦‚æœè´¨é‡è¦æ±‚å¾ˆé«˜æˆ–å›¢é˜Ÿè¾ƒå¤§ï¼Œå¯ä»¥é€‰æ‹©å®Œæ•´æµç¨‹"
        }
        
        base_reason = reasons.get(flow, "å¯ä»¥è€ƒè™‘æ­¤æµç¨‹")
        
        if score > 0.5:
            return f"{base_reason}ï¼ˆåŒ¹é…åº¦ï¼š{score:.1%}ï¼‰"
        else:
            return f"{base_reason}ï¼ˆåŒ¹é…åº¦è¾ƒä½ï¼š{score:.1%}ï¼‰"

# å…¨å±€å¼•æ“å®ä¾‹
_engine_instance = None

def get_decision_engine(project_root: Path = None) -> RuleBasedDecisionEngine:
    """è·å–å†³ç­–å¼•æ“å•ä¾‹"""
    global _engine_instance
    
    if _engine_instance is None:
        _engine_instance = RuleBasedDecisionEngine(project_root)
    
    return _engine_instance

def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    engine = get_decision_engine()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "ä¿®å¤ç”¨æˆ·ç™»å½•é¡µé¢çš„æ˜¾ç¤ºé”™è¯¯",
        "ä¸ºç§»åŠ¨åº”ç”¨æ·»åŠ æ¨é€é€šçŸ¥åŠŸèƒ½",
        "é‡æ„æ”¯ä»˜æ¨¡å—çš„ä»£ç ç»“æ„",
        "ç¼–å†™APIæ¥å£çš„å•å…ƒæµ‹è¯•",
        "æ›´æ–°é¡¹ç›®çš„æŠ€æœ¯æ–‡æ¡£",
        "è°ƒç ”æ–°çš„å‰ç«¯æ¡†æ¶",
        "è®¾è®¡å¾®æœåŠ¡æ¶æ„",
        "éƒ¨ç½²åº”ç”¨åˆ°ç”Ÿäº§ç¯å¢ƒ"
    ]
    
    print("ğŸ¤– AceFlowåŸºäºè§„åˆ™çš„å†³ç­–å¼•æ“æµ‹è¯•")
    print("=" * 50)
    
    for i, task in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {task}")
        print("-" * 30)
        
        result = engine.make_decision(task)
        print(f"æ¨èæµç¨‹: {result.recommended_flow}")
        print(f"ç½®ä¿¡åº¦: {result.confidence:.1%}")
        print(f"æ¨ç†: {result.reasoning}")
        print(f"é¢„ä¼°æ—¶é—´: {result.estimated_hours}å°æ—¶")
        print(f"æµç¨‹æ­¥éª¤: {len(result.steps)}ä¸ªæ­¥éª¤")
        
        if result.alternatives:
            print("æ›¿ä»£æ–¹æ¡ˆ:")
            for alt in result.alternatives:
                print(f"  - {alt['flow']}: {alt['reason']}")

if __name__ == "__main__":
    main()