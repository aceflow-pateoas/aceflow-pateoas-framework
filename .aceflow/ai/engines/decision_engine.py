"""
AceFlow v2.0 æ™ºèƒ½å†³ç­–å¼•æ“
ä»è§„åˆ™å¼•æ“å‡çº§ä¸ºæœºå™¨å­¦ä¹ é©±åŠ¨çš„æ™ºèƒ½ç³»ç»Ÿ
"""

import json
import yaml
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
from enum import Enum

# å¯¼å…¥AIç›¸å…³åº“ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦å®‰è£…ï¼‰
try:
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score
    HAS_ML_LIBS = True
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£…MLåº“ï¼Œä½¿ç”¨ç®€åŒ–çš„è§„åˆ™å¼•æ“
    HAS_ML_LIBS = False
    np = None

class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    FEATURE_DEVELOPMENT = "feature_development"
    BUG_FIX = "bug_fix"
    REFACTORING = "refactoring"
    TESTING = "testing"
    DOCUMENTATION = "documentation"
    RESEARCH = "research"
    ARCHITECTURE = "architecture"
    DEPLOYMENT = "deployment"

class ProjectComplexity(Enum):
    """é¡¹ç›®å¤æ‚åº¦æšä¸¾"""
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    ENTERPRISE = "enterprise"

@dataclass
class ProjectContext:
    """é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    name: str
    team_size: int
    duration_estimate: str
    technology_stack: List[str]
    project_type: str
    current_stage: str
    completion_percentage: float
    historical_velocity: float
    risk_factors: List[str]
    
    def to_features(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºMLç‰¹å¾"""
        return {
            'team_size': self.team_size,
            'duration_days': self._parse_duration_to_days(self.duration_estimate),
            'completion_percentage': self.completion_percentage,
            'historical_velocity': self.historical_velocity,
            'has_frontend': any('frontend' in tech.lower() or 'react' in tech.lower() or 'vue' in tech.lower() 
                             for tech in self.technology_stack),
            'has_backend': any('backend' in tech.lower() or 'api' in tech.lower() or 'django' in tech.lower() 
                            for tech in self.technology_stack),
            'has_database': any('database' in tech.lower() or 'sql' in tech.lower() or 'mongo' in tech.lower() 
                             for tech in self.technology_stack),
            'risk_count': len(self.risk_factors),
            'is_web_project': self.project_type.lower() in ['web', 'webapp', 'website'],
            'is_mobile_project': self.project_type.lower() in ['mobile', 'app', 'ios', 'android'],
            'is_api_project': self.project_type.lower() in ['api', 'microservice', 'backend']
        }
    
    def _parse_duration_to_days(self, duration: str) -> int:
        """è§£ææŒç»­æ—¶é—´ä¸ºå¤©æ•°"""
        duration = duration.lower()
        if 'week' in duration:
            weeks = int(''.join(filter(str.isdigit, duration)) or 1)
            return weeks * 7
        elif 'month' in duration:
            months = int(''.join(filter(str.isdigit, duration)) or 1)
            return months * 30
        elif 'day' in duration:
            return int(''.join(filter(str.isdigit, duration)) or 1)
        return 7  # é»˜è®¤1å‘¨

@dataclass
class TaskContext:
    """ä»»åŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    description: str
    priority: str
    estimated_effort: str
    dependencies: List[str]
    technical_complexity: str
    user_impact: str
    
    def to_features(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºMLç‰¹å¾"""
        return {
            'description_length': len(self.description),
            'priority_high': self.priority.lower() == 'high',
            'priority_medium': self.priority.lower() == 'medium',
            'priority_low': self.priority.lower() == 'low',
            'has_dependencies': len(self.dependencies) > 0,
            'dependency_count': len(self.dependencies),
            'complexity_high': self.technical_complexity.lower() == 'high',
            'complexity_medium': self.technical_complexity.lower() == 'medium',
            'complexity_low': self.technical_complexity.lower() == 'low',
            'impact_high': self.user_impact.lower() == 'high',
            'impact_medium': self.user_impact.lower() == 'medium',
            'impact_low': self.user_impact.lower() == 'low',
            'has_keywords_bug': 'bug' in self.description.lower() or 'fix' in self.description.lower(),
            'has_keywords_feature': 'feature' in self.description.lower() or 'add' in self.description.lower(),
            'has_keywords_test': 'test' in self.description.lower() or 'testing' in self.description.lower(),
            'has_keywords_doc': 'doc' in self.description.lower() or 'documentation' in self.description.lower()
        }

@dataclass
class AIDecision:
    """AIå†³ç­–ç»“æœ"""
    recommended_flow: str
    confidence: float
    reasoning: str
    alternatives: List[Dict[str, Any]]
    estimated_duration: int
    suggested_tasks: List[str]
    risk_assessment: Dict[str, float]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'recommended_flow': self.recommended_flow,
            'confidence': self.confidence,
            'reasoning': self.reasoning,
            'alternatives': self.alternatives,
            'estimated_duration': self.estimated_duration,
            'suggested_tasks': self.suggested_tasks,
            'risk_assessment': self.risk_assessment,
            'timestamp': datetime.now().isoformat()
        }

class TaskClassificationModel:
    """ä»»åŠ¡åˆ†ç±»æ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.is_trained = False
        
    def train(self, training_data: List[Tuple[str, TaskType]]):
        """è®­ç»ƒä»»åŠ¡åˆ†ç±»æ¨¡å‹"""
        if not HAS_ML_LIBS:
            logging.warning("ML libraries not available, using rule-based classification")
            return
            
        descriptions, labels = zip(*training_data)
        
        # æ–‡æœ¬å‘é‡åŒ–
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        X = self.vectorizer.fit_transform(descriptions)
        
        # è®­ç»ƒåˆ†ç±»å™¨
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X, labels)
        self.is_trained = True
        
        logging.info(f"Task classification model trained with {len(training_data)} samples")
    
    def predict(self, task_context: TaskContext) -> TaskType:
        """é¢„æµ‹ä»»åŠ¡ç±»å‹"""
        if not self.is_trained or not HAS_ML_LIBS:
            return self._rule_based_classification(task_context)
        
        # ä½¿ç”¨MLæ¨¡å‹é¢„æµ‹
        X = self.vectorizer.transform([task_context.description])
        prediction = self.model.predict(X)[0]
        return TaskType(prediction)
    
    def _rule_based_classification(self, task_context: TaskContext) -> TaskType:
        """åŸºäºè§„åˆ™çš„ä»»åŠ¡åˆ†ç±»ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        description = task_context.description.lower()
        
        # å…³é”®è¯åŒ¹é…è§„åˆ™
        if any(word in description for word in ['bug', 'fix', 'error', 'issue']):
            return TaskType.BUG_FIX
        elif any(word in description for word in ['test', 'testing', 'unit test', 'integration']):
            return TaskType.TESTING
        elif any(word in description for word in ['doc', 'documentation', 'readme', 'guide']):
            return TaskType.DOCUMENTATION
        elif any(word in description for word in ['refactor', 'refactoring', 'cleanup', 'optimize']):
            return TaskType.REFACTORING
        elif any(word in description for word in ['research', 'investigate', 'spike', 'poc']):
            return TaskType.RESEARCH
        elif any(word in description for word in ['architecture', 'design', 'framework']):
            return TaskType.ARCHITECTURE
        elif any(word in description for word in ['deploy', 'deployment', 'release', 'publish']):
            return TaskType.DEPLOYMENT
        else:
            return TaskType.FEATURE_DEVELOPMENT

class FlowRecommendationModel:
    """æµç¨‹æ¨èæ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        
    def train(self, training_data: List[Tuple[Dict[str, Any], str]]):
        """è®­ç»ƒæµç¨‹æ¨èæ¨¡å‹"""
        if not HAS_ML_LIBS:
            logging.warning("ML libraries not available, using rule-based recommendation")
            return
            
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        features = []
        labels = []
        
        for feature_dict, flow_mode in training_data:
            feature_vector = list(feature_dict.values())
            features.append(feature_vector)
            labels.append(flow_mode)
        
        X = np.array(features)
        y = np.array(labels)
        
        # è®­ç»ƒæ¨¡å‹
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X, y)
        self.is_trained = True
        
        logging.info(f"Flow recommendation model trained with {len(training_data)} samples")
    
    def suggest(self, task_type: TaskType, project_context: ProjectContext) -> str:
        """æ¨èå·¥ä½œæµæ¨¡å¼"""
        if not self.is_trained or not HAS_ML_LIBS:
            return self._rule_based_recommendation(task_type, project_context)
        
        # ä½¿ç”¨MLæ¨¡å‹æ¨è
        features = list(project_context.to_features().values())
        prediction = self.model.predict([features])[0]
        return prediction
    
    def _rule_based_recommendation(self, task_type: TaskType, project_context: ProjectContext) -> str:
        """åŸºäºè§„åˆ™çš„æµç¨‹æ¨èï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ç®€å•é¡¹ç›®æˆ–å¿«é€Ÿä¿®å¤
        if (task_type == TaskType.BUG_FIX or 
            project_context.team_size <= 3 or 
            'quick' in project_context.duration_estimate.lower()):
            return 'minimal'
        
        # ä¼ä¸šçº§æˆ–å¤æ‚é¡¹ç›®
        if (project_context.team_size > 10 or 
            task_type == TaskType.ARCHITECTURE or
            len(project_context.risk_factors) > 3):
            return 'complete'
        
        # é»˜è®¤æ ‡å‡†æ¨¡å¼
        return 'standard'

class ProgressPredictionModel:
    """è¿›åº¦é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        
    def train(self, training_data: List[Tuple[Dict[str, Any], int]]):
        """è®­ç»ƒè¿›åº¦é¢„æµ‹æ¨¡å‹"""
        if not HAS_ML_LIBS:
            logging.warning("ML libraries not available, using rule-based prediction")
            return
            
        features = []
        durations = []
        
        for feature_dict, actual_duration in training_data:
            feature_vector = list(feature_dict.values())
            features.append(feature_vector)
            durations.append(actual_duration)
        
        X = np.array(features)
        y = np.array(durations)
        
        # ä½¿ç”¨å›å½’æ¨¡å‹é¢„æµ‹æŒç»­æ—¶é—´
        from sklearn.ensemble import RandomForestRegressor
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.model.fit(X, y)
        self.is_trained = True
        
        logging.info(f"Progress prediction model trained with {len(training_data)} samples")
    
    def estimate(self, task_type: TaskType, project_context: ProjectContext) -> int:
        """ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´ï¼ˆå°æ—¶ï¼‰"""
        if not self.is_trained or not HAS_ML_LIBS:
            return self._rule_based_estimation(task_type, project_context)
        
        # ä½¿ç”¨MLæ¨¡å‹é¢„æµ‹
        features = list(project_context.to_features().values())
        prediction = self.model.predict([features])[0]
        return max(1, int(prediction))  # è‡³å°‘1å°æ—¶
    
    def _rule_based_estimation(self, task_type: TaskType, project_context: ProjectContext) -> int:
        """åŸºäºè§„åˆ™çš„æ—¶é—´ä¼°ç®—ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        base_hours = {
            TaskType.BUG_FIX: 4,
            TaskType.FEATURE_DEVELOPMENT: 16,
            TaskType.REFACTORING: 8,
            TaskType.TESTING: 6,
            TaskType.DOCUMENTATION: 4,
            TaskType.RESEARCH: 12,
            TaskType.ARCHITECTURE: 24,
            TaskType.DEPLOYMENT: 8
        }
        
        hours = base_hours.get(task_type, 8)
        
        # æ ¹æ®å›¢é˜Ÿè§„æ¨¡è°ƒæ•´
        if project_context.team_size > 5:
            hours *= 1.2  # å¤§å›¢é˜Ÿåè°ƒæˆæœ¬
        elif project_context.team_size == 1:
            hours *= 0.8  # å•äººé¡¹ç›®æ•ˆç‡é«˜
        
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´
        if len(project_context.risk_factors) > 2:
            hours *= 1.5  # é«˜é£é™©é¡¹ç›®
        
        return int(hours)

class AIDecisionEngine:
    """AIå†³ç­–å¼•æ“ä¸»ç±»"""
    
    def __init__(self, aceflow_dir: Path):
        self.aceflow_dir = aceflow_dir
        self.ai_dir = aceflow_dir / "ai"
        self.models_dir = self.ai_dir / "models"
        self.data_dir = self.ai_dir / "data"
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.task_classifier = TaskClassificationModel()
        self.flow_recommender = FlowRecommendationModel()
        self.progress_predictor = ProgressPredictionModel()
        
        # åˆ›å»ºç›®å½•
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self._load_models()
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = self.ai_dir / "ai_engine.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _load_models(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # å°è¯•åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
            # è¿™é‡Œå¯ä»¥ä»æ–‡ä»¶åŠ è½½ä¿å­˜çš„æ¨¡å‹
            self.logger.info("Models loaded successfully")
        except Exception as e:
            self.logger.warning(f"Could not load pre-trained models: {e}")
            # ä½¿ç”¨é»˜è®¤çš„è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹
            self._initialize_with_default_data()
    
    def _initialize_with_default_data(self):
        """ä½¿ç”¨é»˜è®¤æ•°æ®åˆå§‹åŒ–æ¨¡å‹"""
        # é»˜è®¤ä»»åŠ¡åˆ†ç±»è®­ç»ƒæ•°æ®
        task_training_data = [
            ("Fix login bug", TaskType.BUG_FIX),
            ("Add user authentication", TaskType.FEATURE_DEVELOPMENT),
            ("Refactor database layer", TaskType.REFACTORING),
            ("Write unit tests for API", TaskType.TESTING),
            ("Update API documentation", TaskType.DOCUMENTATION),
            ("Research new framework", TaskType.RESEARCH),
            ("Design system architecture", TaskType.ARCHITECTURE),
            ("Deploy to production", TaskType.DEPLOYMENT)
        ]
        
        # è®­ç»ƒä»»åŠ¡åˆ†ç±»æ¨¡å‹
        self.task_classifier.train(task_training_data)
        
        self.logger.info("Models initialized with default training data")
    
    def make_decision(self, 
                     task_context: TaskContext, 
                     project_context: ProjectContext) -> AIDecision:
        """åšå‡ºAIå†³ç­–"""
        
        try:
            # 1. ä»»åŠ¡åˆ†ç±»
            task_type = self.task_classifier.predict(task_context)
            
            # 2. æµç¨‹æ¨è
            recommended_flow = self.flow_recommender.suggest(task_type, project_context)
            
            # 3. æ—¶é—´ä¼°ç®—
            estimated_duration = self.progress_predictor.estimate(task_type, project_context)
            
            # 4. è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(task_context, project_context)
            
            # 5. ç”Ÿæˆæ¨ç†è§£é‡Š
            reasoning = self._explain_decision(task_type, recommended_flow, project_context)
            
            # 6. æä¾›æ›¿ä»£æ–¹æ¡ˆ
            alternatives = self._suggest_alternatives(recommended_flow, task_type)
            
            # 7. ç”Ÿæˆä»»åŠ¡å»ºè®®
            suggested_tasks = self._generate_task_suggestions(task_type, recommended_flow)
            
            # 8. é£é™©è¯„ä¼°
            risk_assessment = self._assess_risks(task_context, project_context)
            
            decision = AIDecision(
                recommended_flow=recommended_flow,
                confidence=confidence,
                reasoning=reasoning,
                alternatives=alternatives,
                estimated_duration=estimated_duration,
                suggested_tasks=suggested_tasks,
                risk_assessment=risk_assessment
            )
            
            # è®°å½•å†³ç­–
            self._log_decision(decision, task_context, project_context)
            
            return decision
            
        except Exception as e:
            self.logger.error(f"Error in AI decision making: {e}")
            # è¿”å›é»˜è®¤å†³ç­–
            return self._get_default_decision()
    
    def _calculate_confidence(self, task_context: TaskContext, project_context: ProjectContext) -> float:
        """è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        confidence = 0.7  # åŸºç¡€ç½®ä¿¡åº¦
        
        # æ ¹æ®é¡¹ç›®ä¿¡æ¯å®Œæ•´æ€§è°ƒæ•´
        if project_context.historical_velocity > 0:
            confidence += 0.1
        
        if len(project_context.technology_stack) > 0:
            confidence += 0.1
            
        if task_context.priority in ['high', 'medium', 'low']:
            confidence += 0.05
            
        # æ ¹æ®æè¿°è¯¦ç»†ç¨‹åº¦è°ƒæ•´
        if len(task_context.description) > 50:
            confidence += 0.05
            
        return min(0.95, confidence)  # æœ€é«˜95%ç½®ä¿¡åº¦
    
    def _explain_decision(self, task_type: TaskType, recommended_flow: str, project_context: ProjectContext) -> str:
        """ç”Ÿæˆå†³ç­–æ¨ç†è§£é‡Š"""
        explanations = {
            'minimal': f"æ¨èè½»é‡çº§æµç¨‹ï¼Œå› ä¸º{self._get_minimal_reason(task_type, project_context)}",
            'standard': f"æ¨èæ ‡å‡†æµç¨‹ï¼Œå› ä¸º{self._get_standard_reason(task_type, project_context)}",
            'complete': f"æ¨èå®Œæ•´æµç¨‹ï¼Œå› ä¸º{self._get_complete_reason(task_type, project_context)}"
        }
        
        return explanations.get(recommended_flow, "åŸºäºé¡¹ç›®ç‰¹æ€§æ¨èæ­¤æµç¨‹æ¨¡å¼")
    
    def _get_minimal_reason(self, task_type: TaskType, project_context: ProjectContext) -> str:
        """è·å–è½»é‡çº§æµç¨‹æ¨èåŸå› """
        reasons = []
        
        if task_type == TaskType.BUG_FIX:
            reasons.append("è¿™æ˜¯ä¸€ä¸ªç´§æ€¥ä¿®å¤ä»»åŠ¡")
        if project_context.team_size <= 3:
            reasons.append("å›¢é˜Ÿè§„æ¨¡è¾ƒå°")
        if 'week' in project_context.duration_estimate and '1' in project_context.duration_estimate:
            reasons.append("é¡¹ç›®å‘¨æœŸè¾ƒçŸ­")
            
        return "ï¼Œ".join(reasons) if reasons else "é¡¹ç›®é€‚åˆå¿«é€Ÿè¿­ä»£"
    
    def _get_standard_reason(self, task_type: TaskType, project_context: ProjectContext) -> str:
        """è·å–æ ‡å‡†æµç¨‹æ¨èåŸå› """
        reasons = []
        
        if task_type == TaskType.FEATURE_DEVELOPMENT:
            reasons.append("è¿™æ˜¯åŠŸèƒ½å¼€å‘ä»»åŠ¡")
        if 3 < project_context.team_size <= 10:
            reasons.append("å›¢é˜Ÿè§„æ¨¡é€‚ä¸­")
        if 'month' in project_context.duration_estimate:
            reasons.append("é¡¹ç›®éœ€è¦é€‚åº¦çš„è´¨é‡æ§åˆ¶")
            
        return "ï¼Œ".join(reasons) if reasons else "é¡¹ç›®éœ€è¦å¹³è¡¡æ•ˆç‡å’Œè´¨é‡"
    
    def _get_complete_reason(self, task_type: TaskType, project_context: ProjectContext) -> str:
        """è·å–å®Œæ•´æµç¨‹æ¨èåŸå› """
        reasons = []
        
        if project_context.team_size > 10:
            reasons.append("å¤§å‹å›¢é˜Ÿéœ€è¦ä¸¥æ ¼åè°ƒ")
        if len(project_context.risk_factors) > 3:
            reasons.append("é¡¹ç›®é£é™©è¾ƒé«˜")
        if task_type == TaskType.ARCHITECTURE:
            reasons.append("æ¶æ„è®¾è®¡éœ€è¦ä¸¥æ ¼æµç¨‹")
            
        return "ï¼Œ".join(reasons) if reasons else "é¡¹ç›®éœ€è¦ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶"
    
    def _suggest_alternatives(self, recommended_flow: str, task_type: TaskType) -> List[Dict[str, Any]]:
        """æä¾›æ›¿ä»£æµç¨‹æ–¹æ¡ˆ"""
        all_flows = ['minimal', 'standard', 'complete']
        alternatives = []
        
        for flow in all_flows:
            if flow != recommended_flow:
                alternatives.append({
                    'flow': flow,
                    'reason': self._get_alternative_reason(flow, task_type),
                    'confidence': 0.3 if flow == 'complete' else 0.5
                })
        
        return alternatives[:2]  # æœ€å¤š2ä¸ªæ›¿ä»£æ–¹æ¡ˆ
    
    def _get_alternative_reason(self, flow: str, task_type: TaskType) -> str:
        """è·å–æ›¿ä»£æ–¹æ¡ˆæ¨èåŸå› """
        reasons = {
            'minimal': "å¦‚æœéœ€è¦å¿«é€Ÿäº¤ä»˜ï¼Œå¯è€ƒè™‘è½»é‡çº§æµç¨‹",
            'standard': "å¦‚æœéœ€è¦å¹³è¡¡æ•ˆç‡å’Œè´¨é‡ï¼Œå¯è€ƒè™‘æ ‡å‡†æµç¨‹", 
            'complete': "å¦‚æœè´¨é‡è¦æ±‚æé«˜ï¼Œå¯è€ƒè™‘å®Œæ•´æµç¨‹"
        }
        return reasons.get(flow, "å¯æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©")
    
    def _generate_task_suggestions(self, task_type: TaskType, recommended_flow: str) -> List[str]:
        """ç”Ÿæˆä»»åŠ¡å»ºè®®"""
        base_suggestions = {
            TaskType.FEATURE_DEVELOPMENT: [
                "æ˜ç¡®åŠŸèƒ½éœ€æ±‚å’ŒéªŒæ”¶æ ‡å‡†",
                "è®¾è®¡ç”¨æˆ·ç•Œé¢å’Œäº¤äº’æµç¨‹",
                "ç¼–å†™æ ¸å¿ƒåŠŸèƒ½ä»£ç ",
                "è¿›è¡ŒåŠŸèƒ½æµ‹è¯•å’Œç”¨æˆ·éªŒè¯"
            ],
            TaskType.BUG_FIX: [
                "é‡ç°å’Œåˆ†æé—®é¢˜",
                "å®šä½é—®é¢˜æ ¹æœ¬åŸå› ",
                "å®æ–½ä¿®å¤æ–¹æ¡ˆ",
                "éªŒè¯ä¿®å¤æ•ˆæœ"
            ],
            TaskType.REFACTORING: [
                "åˆ†æå½“å‰ä»£ç ç»“æ„",
                "åˆ¶å®šé‡æ„è®¡åˆ’",
                "é€æ­¥é‡æ„å®æ–½",
                "å›å½’æµ‹è¯•éªŒè¯"
            ]
        }
        
        suggestions = base_suggestions.get(task_type, [
            "åˆ†æä»»åŠ¡éœ€æ±‚",
            "åˆ¶å®šå®æ–½è®¡åˆ’", 
            "æ‰§è¡Œå…·ä½“å·¥ä½œ",
            "éªŒè¯å®Œæˆæ•ˆæœ"
        ])
        
        # æ ¹æ®æµç¨‹æ¨¡å¼è°ƒæ•´å»ºè®®æ•°é‡
        if recommended_flow == 'minimal':
            return suggestions[:3]
        elif recommended_flow == 'standard':
            return suggestions
        else:  # complete
            return suggestions + ["è¯¦ç»†æ–‡æ¡£è®°å½•", "å›¢é˜Ÿè¯„å®¡ç¡®è®¤"]
    
    def _assess_risks(self, task_context: TaskContext, project_context: ProjectContext) -> Dict[str, float]:
        """è¯„ä¼°é¡¹ç›®é£é™©"""
        risks = {
            'schedule_risk': 0.3,  # è¿›åº¦é£é™©
            'technical_risk': 0.2, # æŠ€æœ¯é£é™©
            'quality_risk': 0.2,   # è´¨é‡é£é™©
            'resource_risk': 0.1   # èµ„æºé£é™©
        }
        
        # æ ¹æ®é¡¹ç›®ç‰¹å¾è°ƒæ•´é£é™©
        if task_context.technical_complexity == 'high':
            risks['technical_risk'] += 0.3
            
        if len(task_context.dependencies) > 2:
            risks['schedule_risk'] += 0.2
            
        if project_context.team_size < 2:
            risks['resource_risk'] += 0.3
            
        if len(project_context.risk_factors) > 2:
            for risk_type in risks:
                risks[risk_type] += 0.1
        
        # ç¡®ä¿é£é™©å€¼åœ¨0-1èŒƒå›´å†…
        return {k: min(1.0, v) for k, v in risks.items()}
    
    def _log_decision(self, decision: AIDecision, task_context: TaskContext, project_context: ProjectContext):
        """è®°å½•AIå†³ç­–ç”¨äºåç»­å­¦ä¹ """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'task_context': {
                'description': task_context.description,
                'priority': task_context.priority,
                'complexity': task_context.technical_complexity
            },
            'project_context': {
                'team_size': project_context.team_size,
                'duration_estimate': project_context.duration_estimate,
                'current_stage': project_context.current_stage
            },
            'decision': decision.to_dict()
        }
        
        # ä¿å­˜åˆ°å†³ç­–æ—¥å¿—æ–‡ä»¶
        log_file = self.data_dir / "decision_log.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def _get_default_decision(self) -> AIDecision:
        """è·å–é»˜è®¤å†³ç­–ï¼ˆé”™è¯¯æƒ…å†µä¸‹çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        return AIDecision(
            recommended_flow='standard',
            confidence=0.5,
            reasoning='ä½¿ç”¨é»˜è®¤æ ‡å‡†æµç¨‹',
            alternatives=[],
            estimated_duration=16,
            suggested_tasks=['åˆ†æéœ€æ±‚', 'å®æ–½å¼€å‘', 'æµ‹è¯•éªŒè¯'],
            risk_assessment={'schedule_risk': 0.3, 'technical_risk': 0.3, 'quality_risk': 0.2, 'resource_risk': 0.2}
        )
    
    def get_personalized_suggestions(self, project_context: ProjectContext) -> List[str]:
        """è·å–ä¸ªæ€§åŒ–å»ºè®®"""
        suggestions = []
        
        # åŸºäºå†å²è¡¨ç°çš„å»ºè®®
        if project_context.historical_velocity < 0.8:
            suggestions.append("ğŸš€ å»ºè®®ä¼˜åŒ–å›¢é˜Ÿæ•ˆç‡ï¼Œå½“å‰è¿›åº¦ç•¥ä½äºé¢„æœŸ")
            
        if project_context.completion_percentage > 0.8:
            suggestions.append("ğŸ¯ é¡¹ç›®å³å°†å®Œæˆï¼Œå»ºè®®é‡ç‚¹å…³æ³¨è´¨é‡éªŒè¯")
            
        # åŸºäºå›¢é˜Ÿè§„æ¨¡çš„å»ºè®®
        if project_context.team_size == 1:
            suggestions.append("ğŸ‘¤ å•äººé¡¹ç›®å»ºè®®ä½¿ç”¨è½»é‡çº§æµç¨‹æé«˜æ•ˆç‡")
        elif project_context.team_size > 10:
            suggestions.append("ğŸ‘¥ å¤§å‹å›¢é˜Ÿå»ºè®®åŠ å¼ºæ²Ÿé€šåè°ƒæœºåˆ¶")
            
        # åŸºäºæŠ€æœ¯æ ˆçš„å»ºè®®
        if any('new' in tech.lower() or 'experimental' in tech.lower() for tech in project_context.technology_stack):
            suggestions.append("ğŸ”¬ ä½¿ç”¨æ–°æŠ€æœ¯å»ºè®®å¢åŠ ç ”ç©¶å’Œæµ‹è¯•æ—¶é—´")
            
        return suggestions[:3]  # æœ€å¤šè¿”å›3æ¡å»ºè®®

# å…¨å±€AIå¼•æ“å®ä¾‹
_ai_engine_instance = None

def get_ai_engine(aceflow_dir: Path = None) -> AIDecisionEngine:
    """è·å–AIå¼•æ“å•ä¾‹"""
    global _ai_engine_instance
    
    if _ai_engine_instance is None:
        if aceflow_dir is None:
            aceflow_dir = Path.cwd() / ".aceflow"
        _ai_engine_instance = AIDecisionEngine(aceflow_dir)
    
    return _ai_engine_instance